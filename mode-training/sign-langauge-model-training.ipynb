{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T03:58:28.181725Z",
     "iopub.status.busy": "2025-01-04T03:58:28.181436Z",
     "iopub.status.idle": "2025-01-04T03:58:33.282744Z",
     "shell.execute_reply": "2025-01-04T03:58:33.281890Z",
     "shell.execute_reply.started": "2025-01-04T03:58:28.181694Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting XlsxWriter\n",
      "  Downloading XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: XlsxWriter\n",
      "Successfully installed XlsxWriter-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install XlsxWriter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Load the required libraray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T03:58:33.284592Z",
     "iopub.status.busy": "2025-01-04T03:58:33.284238Z",
     "iopub.status.idle": "2025-01-04T03:58:33.290895Z",
     "shell.execute_reply": "2025-01-04T03:58:33.290068Z",
     "shell.execute_reply.started": "2025-01-04T03:58:33.284558Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from datetime import datetime\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T03:58:33.292920Z",
     "iopub.status.busy": "2025-01-04T03:58:33.292712Z",
     "iopub.status.idle": "2025-01-04T03:58:36.785331Z",
     "shell.execute_reply": "2025-01-04T03:58:36.784615Z",
     "shell.execute_reply.started": "2025-01-04T03:58:33.292902Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/sign-langauge-translater/combined_dataset.csv')\n",
    "# df2 = pd.read_csv('hand_landmarks_from_4500_to_5000.csv')\n",
    "\n",
    "# df = pd.concat([df1, df2], ignore_index=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T03:58:36.786907Z",
     "iopub.status.busy": "2025-01-04T03:58:36.786612Z",
     "iopub.status.idle": "2025-01-04T03:58:36.803115Z",
     "shell.execute_reply": "2025-01-04T03:58:36.802472Z",
     "shell.execute_reply.started": "2025-01-04T03:58:36.786877Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>landmarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>[[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>[[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>[[[[0.5544530153274536, 0.8488561511039734, -6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>[[[[0.558426558971405, 0.804563581943512, -5.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>[[[[0.5819562673568726, 0.8947145342826843, -6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                          landmarks\n",
       "0     a  [[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0],...\n",
       "1     a  [[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0],...\n",
       "2     a  [[[[0.5544530153274536, 0.8488561511039734, -6...\n",
       "3     a  [[[[0.558426558971405, 0.804563581943512, -5.1...\n",
       "4     a  [[[[0.5819562673568726, 0.8947145342826843, -6..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines a function preprocess_data that processes a dataset by:\n",
    "\n",
    "Converting the landmarks, stored as strings, into numeric format using ast.literal_eval and numpy.\n",
    "Encoding the class labels into numeric values using LabelEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T03:58:36.804296Z",
     "iopub.status.busy": "2025-01-04T03:58:36.804034Z",
     "iopub.status.idle": "2025-01-04T03:59:41.354727Z",
     "shell.execute_reply": "2025-01-04T03:59:41.353825Z",
     "shell.execute_reply.started": "2025-01-04T03:58:36.804253Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(df, landmarks_column=\"landmarks\", class_column=\"class\"):\n",
    "    \"\"\"\n",
    "    Preprocess the dataset for model training.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with class labels and landmarks columns.\n",
    "        landmarks_column (str): Name of the column containing landmarks.\n",
    "        class_column (str): Name of the column containing class labels.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Processed DataFrame with numeric landmarks and encoded labels.\n",
    "        LabelEncoder: Encoder for decoding class labels.\n",
    "    \"\"\"\n",
    "    # Ensure landmarks are in numeric format\n",
    "    df[landmarks_column] = df[landmarks_column].apply(\n",
    "        lambda x: np.array(ast.literal_eval(x)) if isinstance(x, str) else np.array(x)\n",
    "    )\n",
    "\n",
    "    # Encode class labels\n",
    "    le = LabelEncoder()\n",
    "    df[\"encoded_class\"] = le.fit_transform(df[class_column])\n",
    "\n",
    "    return df, le\n",
    "\n",
    "# Apply the preprocessing\n",
    "df, label_encoder = preprocess_data(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code snippet calculates and prints the number of unique classes in the dataset using the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T03:59:41.355967Z",
     "iopub.status.busy": "2025-01-04T03:59:41.355650Z",
     "iopub.status.idle": "2025-01-04T03:59:41.361194Z",
     "shell.execute_reply": "2025-01-04T03:59:41.360467Z",
     "shell.execute_reply.started": "2025-01-04T03:59:41.355935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a' 'about' 'aim' 'all' 'and' 'audio' 'b' 'barrier' 'break' 'c' 'can'\n",
      " 'communication' 'creative' 'd' 'detect' 'developed' 'e' 'f' 'g' 'h'\n",
      " 'have' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'our' 'p' 'project' 'q' 'r' 's'\n",
      " 'sign language' 'solution' 't' 'team' 'text' 'that' 'to' 'translate' 'u'\n",
      " 'v' 'w' 'what' 'x' 'y' 'you' 'z'] 50\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(label_encoder.classes_)\n",
    "print(label_encoder.classes_, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines a function augment_landmarks that applies random augmentations to a set of landmarks. Here's a summary of its operation:\n",
    "\n",
    "Data Type Conversion: The landmarks are converted to float64 to ensure precision during operations.\n",
    "\n",
    "Add Random Noise: Small random noise is added to each coordinate in the landmarks array, with the magnitude of noise controlled by max_noise.\n",
    "\n",
    "Apply Random Scaling: The entire set of landmarks is scaled by a random factor within a specified range, defined by scale_range.\n",
    "\n",
    "Return Augmented Landmarks: The function returns the augmented landmarks with both noise and scaling applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T03:59:41.362094Z",
     "iopub.status.busy": "2025-01-04T03:59:41.361905Z",
     "iopub.status.idle": "2025-01-04T03:59:41.376099Z",
     "shell.execute_reply": "2025-01-04T03:59:41.375342Z",
     "shell.execute_reply.started": "2025-01-04T03:59:41.362077Z"
    }
   },
   "outputs": [],
   "source": [
    "def augment_landmarks(landmarks, max_noise=0.01, scale_range=(0.9, 1.1)):\n",
    "    \"\"\"\n",
    "    Apply random augmentations to landmarks.\n",
    "\n",
    "    Args:\n",
    "        landmarks (np.ndarray): Original landmarks array.\n",
    "        max_noise (float): Maximum noise to add to each coordinate.\n",
    "        scale_range (tuple): Range for random scaling factors.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Augmented landmarks.\n",
    "    \"\"\"\n",
    "    # Ensure landmarks are float64 for operations\n",
    "    landmarks = landmarks.astype(np.float64)\n",
    "    \n",
    "    # Add random noise\n",
    "    noise = np.random.uniform(-max_noise, max_noise, size=landmarks.shape)\n",
    "    landmarks += noise\n",
    "\n",
    "    # Apply random scaling\n",
    "    scale_factor = random.uniform(*scale_range)\n",
    "    landmarks *= scale_factor\n",
    "\n",
    "    return landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The augment_dataset_in_batches function augments landmarks in a dataset by generating multiple augmented versions for each original row, processing the data in batches to avoid memory overflow. It yields each batch as a DataFrame until all rows are processed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T03:59:41.378390Z",
     "iopub.status.busy": "2025-01-04T03:59:41.378154Z",
     "iopub.status.idle": "2025-01-04T03:59:41.392520Z",
     "shell.execute_reply": "2025-01-04T03:59:41.391802Z",
     "shell.execute_reply.started": "2025-01-04T03:59:41.378370Z"
    }
   },
   "outputs": [],
   "source": [
    "def augment_dataset_in_batches(df, num_augmentations=5, batch_size=1000):\n",
    "    \"\"\"\n",
    "    Augment the dataset in batches to avoid memory overflow.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with 'class' and 'landmarks' columns.\n",
    "        num_augmentations (int): Number of augmented rows to create per original row.\n",
    "        batch_size (int): Number of augmented rows to process in a batch.\n",
    "\n",
    "    Yields:\n",
    "        pd.DataFrame: DataFrame containing a batch of augmented data.\n",
    "    \"\"\"\n",
    "    augmented_rows = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        original_landmarks = np.array(row[\"landmarks\"])\n",
    "        \n",
    "        for _ in range(num_augmentations):\n",
    "            augmented_landmarks = augment_landmarks(original_landmarks)\n",
    "            new_row = {\n",
    "                \"class\": row[\"class\"],\n",
    "                \"landmarks\": augmented_landmarks.tolist(),\n",
    "                \"encoded_class\": row.get(\"encoded_class\", None)\n",
    "            }\n",
    "            augmented_rows.append(new_row)\n",
    "            \n",
    "            # Yield batch when it reaches the specified size\n",
    "            if len(augmented_rows) >= batch_size:\n",
    "                yield pd.DataFrame(augmented_rows)\n",
    "                augmented_rows = []\n",
    "    \n",
    "    # Yield remaining rows\n",
    "    if augmented_rows:\n",
    "        yield pd.DataFrame(augmented_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The save_augmented_data function saves augmented data to a CSV file in batches. It iterates through batches of augmented data generated by augment_dataset_in_batches and appends each batch to the specified CSV file, writing the header only for the first batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T03:59:41.394091Z",
     "iopub.status.busy": "2025-01-04T03:59:41.393878Z",
     "iopub.status.idle": "2025-01-04T03:59:41.405372Z",
     "shell.execute_reply": "2025-01-04T03:59:41.404689Z",
     "shell.execute_reply.started": "2025-01-04T03:59:41.394064Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_augmented_data(df, num_augmentations=5, batch_size=1000, output_file=\"augmented_data.csv\"):\n",
    "    with open(output_file, 'w', newline='') as csvfile:\n",
    "        for idx, batch in enumerate(augment_dataset_in_batches(df, num_augmentations, batch_size)):\n",
    "            # Write header only for the first batch\n",
    "            batch.to_csv(csvfile, mode='a', header=(idx == 0), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This line calls the save_augmented_data function to augment the dataset df. It generates 50 augmented versions of each row, processes them in batches of 1000, and saves the augmented data to a CSV file named augmented_data.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-04T04:12:23.706Z",
     "iopub.execute_input": "2025-01-04T03:59:41.406343Z",
     "iopub.status.busy": "2025-01-04T03:59:41.406116Z"
    }
   },
   "outputs": [],
   "source": [
    "save_augmented_data(df, num_augmentations=50, batch_size=1000, output_file=\"augmented_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code snippet defines constants for processing time series data: timesteps (50) for the number of sequential time steps, frames (21) for the number of frames per time step, and features (3) for the number of features (e.g., x, y, z coordinates) in each frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-04T04:12:23.707Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define timesteps, frames, and features\n",
    "timesteps = 50  # Time steps\n",
    "frames = 21  # Number of frames per time step\n",
    "features = 3  # Number of features per frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code splits the dataset df_org_augmented into training and validation sets, with 80% for training and 20% for validation, using a random seed of 42 for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-04T04:12:23.707Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "df_train, df_val = train_test_split(df_org_augmented, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code prepares the training and validation datasets for a machine learning model. It converts the \"landmarks\" data from df_train and df_val into NumPy arrays, reshaping each landmark into a 3D array of shape (50, 21, 6) representing timesteps, frames, and features. It then extracts the corresponding encoded class labels for training (y_train) and validation (y_val). Finally, it prints the sizes and shapes of the training and validation sets to verify the data preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-04T04:12:23.707Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare X_train and y_train from the training set\n",
    "X_train = np.array([\n",
    "    np.array(landmark).reshape(50, 21, 6) \n",
    "    for landmark in df_train[\"landmarks\"]\n",
    "])\n",
    "y_train = df_train[\"encoded_class\"].values\n",
    "\n",
    "# Prepare X_val and y_val from the validation set\n",
    "X_val = np.array([\n",
    "    np.array(landmark).reshape(50, 21, 6) \n",
    "    for landmark in df_val[\"landmarks\"]\n",
    "])\n",
    "y_val = df_val[\"encoded_class\"].values\n",
    "\n",
    "# Verify the split and shapes\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Validation set size: {len(X_val)}\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This code flattens the 3D training and validation data into 2D arrays to apply normalization. It uses StandardScaler to fit and transform the training data, and transform the validation data. After scaling, the data is reshaped back into its original 3D shape of (50, 21, 6) for further processing in the machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-04T04:12:23.707Z"
    }
   },
   "outputs": [],
   "source": [
    "# Flatten the data to 2D (samples, timesteps * features)\n",
    "X_train_flattened = X_train.reshape(X_train.shape[0], -1)\n",
    "X_val_flattened = X_val.reshape(X_val.shape[0], -1)\n",
    "\n",
    "# Normalize landmarks (fit_transform on the training set, and transform on validation)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_flattened)\n",
    "X_val_scaled = scaler.transform(X_val_flattened)\n",
    "\n",
    "# Reshape the scaled data back to the original 3D shape (50, 21, 6)\n",
    "X_train = X_train_scaled.reshape(X_train.shape[0], 50, 21, 6)\n",
    "X_val = X_val_scaled.reshape(X_val.shape[0], 50, 21, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code checks and prints the shapes of the X_train and X_val arrays after reshaping to confirm the transformations were successful. It helps ensure that the data is in the correct shape for model input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-04T04:12:23.707Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check the shapes after reshaping\n",
    "print(f\"X_train shape after reshaping: {X_train.shape}\")\n",
    "print(f\"X_val shape after reshaping: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code converts the class labels (y_train and y_val) into one-hot encoded vectors using Keras' to_categorical function. The number of classes (num_classes) is specified, and the resulting one-hot encoded arrays (y_train_one_hot and y_val_one_hot) are ready for use in training and validating a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-04T04:12:23.707Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert labels to one-hot encoding\n",
    "from keras.utils import to_categorical\n",
    "y_train_one_hot = to_categorical(y_train, num_classes)\n",
    "y_val_one_hot = to_categorical(y_val, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines the shape of the input for a Vision Transformer (ViT) model. The input is flattened into a 2D shape where timesteps (50 frames) is the first dimension, and features (21 landmarks with 6 values each) is the second dimension. This is done to match the input format required by the ViT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-04T04:12:23.708Z"
    }
   },
   "outputs": [],
   "source": [
    "# Flatten the 3D input for ViT model (timesteps, features)\n",
    "timesteps = 50  # Number of timesteps (frames)\n",
    "features = 21 * 6  # Features per frame (21 landmarks * 6 values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code reshapes the training and validation data (X_train and X_val) into a format suitable for the Vision Transformer (ViT) model, where each sample is reshaped to have dimensions (-1, timesteps, features). The timesteps is 50 (number of frames), and features is 21 * 6 (features per frame). This prepares the data for input into the ViT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-04T04:12:23.708Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_vit = X_train.reshape(-1, timesteps, features)\n",
    "X_val_vit = X_val.reshape(-1, timesteps, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code builds a Vision Transformer (ViT) model for gesture classification with layers including input, normalization, multi-head attention, feed-forward network, global average pooling, and a softmax output layer. The model is compiled with Adam optimizer and categorical crossentropy loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-04T04:12:23.708Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define Vision Transformer (ViT) Model\n",
    "def build_vit_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Build a Vision Transformer (ViT) model for gesture classification.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): Shape of the input (timesteps, features).\n",
    "        num_classes (int): Number of gesture classes.\n",
    "\n",
    "    Returns:\n",
    "        keras.Model: Compiled model.\n",
    "    \"\"\"\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Add LayerNormalization\n",
    "    x = layers.LayerNormalization()(input_layer)\n",
    "\n",
    "    # Add Transformer block (Multi-Head Attention)\n",
    "    x = layers.MultiHeadAttention(num_heads=8, key_dim=64)(x, x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Add()([input_layer, x])  # Skip connection\n",
    "\n",
    "    # Add Feed-forward Network\n",
    "    x = layers.LayerNormalization()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "\n",
    "    # Add Global Average Pooling and Output Layer\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    output = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Compile the model\n",
    "    model = models.Model(inputs=input_layer, outputs=output)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define input shape and build the ViT model\n",
    "input_shape = (timesteps, features)\n",
    "model = build_vit_model(input_shape, num_classes)\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code sets up a log directory for TensorBoard to track model training. It creates a log path based on the current timestamp and initializes a TensorBoard callback to monitor training, with histogram frequency set to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-04T04:12:23.708Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up the log directory for TensorBoard\n",
    "log_dir = os.path.join(\"logs\", \"fit\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "he code trains the Vision Transformer (ViT) model on the reshaped training data (X_train_vit) and one-hot encoded labels (y_train_one_hot). It uses early stopping based on validation loss with a patience of 5 epochs and restores the best model weights. It also logs the training progress to TensorBoard. The training runs for up to 50 epochs with a batch size of 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-04T04:12:23.708Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_vit,  # Reshaped training data\n",
    "    y_train_one_hot,  # One-hot encoded labels for training\n",
    "    validation_data=(X_val_vit, y_val_one_hot),  # Reshaped validation data and labels\n",
    "    epochs=50,  # Number of epochs\n",
    "    batch_size=8,  # Mini-batch size\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',  # Monitor validation loss\n",
    "            patience=5,  # Stop training if no improvement for 5 epochs\n",
    "            restore_best_weights=True  # Restore the best model weights\n",
    "        ),\n",
    "        tensorboard_callback  # TensorBoard callback\n",
    "    ],\n",
    "    verbose=1  # Display training progress\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code visualizes the training process by plotting two graphs:\n",
    "\n",
    "Training and Validation Loss: It plots the loss values for both training and validation data across epochs.\n",
    "Training and Validation Accuracy: It plots the accuracy values for both training and validation data across epochs.\n",
    "Both plots help evaluate how well the model is learning and whether it is overfitting or underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-04T04:12:23.708Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code saves the trained scaler object to a file named scaler.pkl using the joblib library. The file is stored at the specified path, and a message is printed confirming the save location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-04T04:12:23.708Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Assuming 'scaler' is your scaler object\n",
    "scaler_save_path = \"scaler.pkl\"\n",
    "joblib.dump(scaler, scaler_save_path)\n",
    "print(f\"Scaler saved to: {scaler_save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code saves the entire trained model to a file named my_vit_model.h5 using Keras' save() method. It prints a message confirming the model has been saved to the specified path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-04T04:12:23.708Z"
    }
   },
   "outputs": [],
   "source": [
    "model_save_path = \"my_vit_model.h5\"\n",
    "# Save the entire model\n",
    "model.save(model_save_path)\n",
    "print(f\"Model saved to: {model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code loads the previously saved model from the file my_vit_model.h5 using Keras' load_model() method. It then prints the model's summary to verify its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-04T04:12:23.709Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "loaded_model = tf.keras.models.load_model(model_save_path)\n",
    "\n",
    "# Verify the model structure\n",
    "loaded_model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6420653,
     "sourceId": 10366272,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
